# -*- coding: utf-8 -*-
"""Model_1_for_momentum.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/HuyenTrang457/MCM/blob/main/Model_1_for_momentum.ipynb
"""

!pip install factor_analyzer
!pip install statsmodels
!pip install pingouin
!pip install scipy
!pip install matplotlib
!pip uninstall -y scikit-learn
!pip install scikit-learn==1.3.1
!pip install xgboost pandas matplotlib seaborn scikit-learn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV
from xgboost import XGBRegressor
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Load the dataset
data = pd.read_csv("processed_tennis_data.csv")  # Replace with your file path

# Xem tr∆∞·ªõc d·ªØ li·ªáu
print(data.head())

data['Log_Speed_mph'] = np.log1p(data['Speed_mph'])
data['Log_Speed_mph'] = data['Log_Speed_mph'].fillna(data['Speed_mph'].mean())
data['Interaction_Rally_Speed'] = data['Rally_count'] * data['Speed_mph']
features = [
    'Ace', 'Distance_run', 'Error_rate_of_serve_no.1', 'Rally_count',
    'Server_pt', 'Game_victor', 'Log_Speed_mph', 'Interaction_Rally_Speed'
]
print(data['Log_Speed_mph'] )

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Chu·∫©n h√≥a d·ªØ li·ªáu
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data[features])  # 'features' l√† danh s√°ch c√°c c·ªôt c·∫ßn chu·∫©n h√≥a

# √Åp d·ª•ng PCA
pca = PCA(n_components=len(features))  # S·ªë th√†nh ph·∫ßn ch√≠nh = s·ªë l∆∞·ª£ng bi·∫øn
pca.fit(scaled_data)

# Ph∆∞∆°ng sai gi·∫£i th√≠ch b·ªüi t·ª´ng th√†nh ph·∫ßn ch√≠nh
explained_variance_ratio = pca.explained_variance_ratio_

# Ph∆∞∆°ng sai t√≠ch l≈©y
cumulative_variance = explained_variance_ratio.cumsum()

print("Explained Variance Ratio:", explained_variance_ratio)
print("Cumulative Variance:", cumulative_variance)

import matplotlib.pyplot as plt

# V·∫Ω bi·ªÉu ƒë·ªì
plt.figure(figsize=(10, 6))
plt.bar(range(1, len(features) + 1), explained_variance_ratio, alpha=0.7, label='Individual Variance')
plt.step(range(1, len(features) + 1), cumulative_variance, where='mid', label='Cumulative Variance', color='red')
plt.xlabel('Principal Components')
plt.ylabel('Variance Explained')
plt.title('Explained Variance by Principal Components')
plt.legend()
plt.grid()
plt.show()

# H·ªá s·ªë t·∫£i (loadings)
loadings = pd.DataFrame(
    pca.components_.T,  # Ma tr·∫≠n h·ªá s·ªë t·∫£i t·ª´ PCA
    columns=[f'PC{i+1}' for i in range(len(features))],  # T√™n c√°c th√†nh ph·∫ßn ch√≠nh
    index=features  # T√™n c√°c bi·∫øn g·ªëc
)

# T√≥m t·∫Øt ph∆∞∆°ng sai
variance_summary = pd.DataFrame({
    'Principal Component': [f'PC{i+1}' for i in range(len(features))],
    'Explained Variance Ratio': explained_variance_ratio,
    'Cumulative Variance': cumulative_variance
})

# Hi·ªÉn th·ªã b·∫£ng loadings (PC1-PC3)
print("PCA Loadings (PC1-PC3):")
print(loadings.iloc[:, :3])  # Hi·ªÉn th·ªã ch·ªâ 3 th√†nh ph·∫ßn ch√≠nh ƒë·∫ßu ti√™n

# Hi·ªÉn th·ªã b·∫£ng ph∆∞∆°ng sai
print("\nExplained Variance Summary:")
print(variance_summary)

"""Nh·∫≠n x√©t t·ª´ bi·ªÉu ƒë·ªì v√† b·∫£ng h·ªá s·ªë t·∫£i (loadings)
PC1:
Rally_count (0.6749739) c√≥ ·∫£nh h∆∞·ªüng m·∫°nh nh·∫•t ƒë·∫øn PC1 v√† c√≥ h·ªá s·ªë d∆∞∆°ng l·ªõn nh·∫•t ‚Üí PC1 ƒë·∫°i di·ªán cho y·∫øu t·ªë li√™n quan ƒë·∫øn s·ªë l∆∞·ª£t rally.
Interaction_Rally_Speed (-0.5123316) c√≥ h·ªá s·ªë √¢m l·ªõn, cho th·∫•y t·ªëc ƒë·ªô t∆∞∆°ng t√°c rally t√°c ƒë·ªông ng∆∞·ª£c chi·ªÅu ƒë·∫øn PC1.
PC2:
Ace (0.6220342) c√≥ ·∫£nh h∆∞·ªüng m·∫°nh nh·∫•t, ti·∫øp theo l√† Log_Speed_mph (0.4596065) ‚Üí PC2 c√≥ th·ªÉ ƒë·∫°i di·ªán cho k·ªπ nƒÉng giao b√≥ng v√† t·ªëc ƒë·ªô.
PC3:
Distance_run (0.6272342) v√† Error_rate_of_serve_no.1 (-0.5837080) chi ph·ªëi m·∫°nh ‚Üí PC3 ƒë·∫°i di·ªán cho y·∫øu t·ªë kho·∫£ng c√°ch di chuy·ªÉn v√† t·ª∑ l·ªá l·ªói giao b√≥ng.
Explained Variance Ratio: Cho bi·∫øt t·ª∑ l·ªá ph∆∞∆°ng sai ƒë∆∞·ª£c gi·∫£i th√≠ch b·ªüi t·ª´ng th√†nh ph·∫ßn ch√≠nh.

PC1 (19.05%), PC2 (15.87%), v√† PC3 (15.23%) c√πng gi·∫£i th√≠ch 50.16% ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu ‚Üí 3 th√†nh ph·∫ßn ch√≠nh gi·ªØ l·∫°i m·ªôt n·ª≠a th√¥ng tin t·ª´ d·ªØ li·ªáu ban ƒë·∫ßu.
V·ªõi 5 th√†nh ph·∫ßn ch√≠nh, t·ª∑ l·ªá ph∆∞∆°ng sai t√≠ch l≈©y ƒë·∫°t 77.80% ‚Üí ƒë·ªß ƒë·ªÉ gi·ªØ l·∫°i ph·∫ßn l·ªõn th√¥ng tin.
Cumulative Variance:

Sau PC6, ph∆∞∆°ng sai t√≠ch l≈©y ƒë·∫°t 90.54%. C√°c th√†nh ph·∫ßn t·ª´ PC7 tr·ªü ƒëi ƒë√≥ng g√≥p r·∫•t √≠t ph∆∞∆°ng sai, n√™n c√≥ th·ªÉ lo·∫°i b·ªè.

T√≠nh Momentum_temp b·∫±ng c√°ch m·ªói th√†nh ph·∫ßn ch√≠nh ƒë∆∞·ª£c nh√¢n v·ªõi tr·ªçng s·ªë d·ª±a tr√™n Explained Variance Ratio.
![image.png](data:image/png;base64,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)
"""

weights = pca.explained_variance_ratio_[:6]  # L·∫•y tr·ªçng s·ªë cho 6 th√†nh ph·∫ßn ƒë·∫ßu
data['Momentum_temp'] = (pca.transform(scaled_data)[:, :6] * weights).sum(axis=1)

X = data[features]
y = data['Momentum_temp']

#chia t·∫≠p hu·∫•n luy·ªán
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Ch·ªçn model XGBost ƒë·ªÉ train v√¨ sao?
1. Quan h·ªá phi tuy·∫øn:
XGBoost r·∫•t m·∫°nh trong vi·ªác ph√°t hi·ªán c√°c m·ªëi quan h·ªá phi tuy·∫øn gi·ªØa c√°c bi·∫øn, ƒëi·ªÅu m√† c√°c m√¥ h√¨nh tuy·∫øn t√≠nh kh√¥ng l√†m ƒë∆∞·ª£c.
H·ªó tr·ª£ t∆∞∆°ng t√°c gi·ªØa c√°c ƒë·∫∑c tr∆∞ng (features):
2. B·∫£n ch·∫•t c·ªßa XGBoost l√† x√¢y d·ª±ng c√°c c√¢y quy·∫øt ƒë·ªãnh, gi√∫p n·∫Øm b·∫Øt c√°c t∆∞∆°ng t√°c gi·ªØa c√°c bi·∫øn m√† kh√¥ng c·∫ßn t√≠nh to√°n th·ªß c√¥ng (feature engineering).
3. R·∫•t hi·ªáu qu·∫£ v·ªõi t·∫≠p d·ªØ li·ªáu kh√¥ng qu√° l·ªõn
"""

#D√πng model Xgbost ƒë·ªÉ train m√¥ h√¨nh
# D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm tra
# Initialize XGBoost model
xgb_model = XGBRegressor(random_state=42, n_estimators=200, max_depth=5, learning_rate=0.1)

# Train the model
xgb_model.fit(X_train, y_train)
y_pred_test = xgb_model.predict(X_test)

# T√≠nh c√°c ch·ªâ s·ªë tr√™n t·∫≠p ki·ªÉm tra
r2_test = r2_score(y_test, y_pred_test)
rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)

# So s√°nh v·ªõi t·∫≠p hu·∫•n luy·ªán
y_pred_train = xgb_model.predict(X_train)
r2_train = r2_score(y_train, y_pred_train)
rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)
mae_test = mean_absolute_error(y_test, y_pred_test)
mape_test = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100
print(f"Train R¬≤: {r2_train:.4f}, Train RMSE: {rmse_train:.4f}")
print(f"Test R¬≤: {r2_test:.4f}, Test RMSE: {rmse_test:.4f}")

from sklearn.model_selection import cross_val_score

# T√≠nh R¬≤ v·ªõi Cross-Validation (5 folds)
cv_r2 = cross_val_score(xgb_model, X, y, cv=5, scoring='r2')
cv_rmse = -cross_val_score(xgb_model, X, y, cv=5, scoring='neg_root_mean_squared_error')

print(f"Cross-Validated R¬≤: {cv_r2.mean():.4f} ¬± {cv_r2.std():.4f}")
print(f"Cross-Validated RMSE: {cv_rmse.mean():.4f} ¬± {cv_rmse.std():.4f}")

"""1. Hi·ªáu su·∫•t tr√™n t·∫≠p hu·∫•n luy·ªán
Train R¬≤: 0.9976

M√¥ h√¨nh ƒë√£ gi·∫£i th√≠ch ƒë∆∞·ª£c 99.76% ph∆∞∆°ng sai c·ªßa bi·∫øn m·ª•c ti√™u (Momentum_temp) tr√™n t·∫≠p hu·∫•n luy·ªán.
ƒê√¢y l√† m·ªôt gi√° tr·ªã r·∫•t cao, cho th·∫•y m√¥ h√¨nh ƒë√£ h·ªçc t·ªët tr√™n t·∫≠p hu·∫•n luy·ªán.
Train RMSE: 0.0190

Sai s·ªë trung b√¨nh tr√™n t·∫≠p hu·∫•n luy·ªán ch·ªâ kho·∫£ng 0.019 ƒë∆°n v·ªã, r·∫•t nh·ªè so v·ªõi ph·∫°m vi d·ªØ li·ªáu.
ƒêi·ªÅu n√†y kh·∫≥ng ƒë·ªãnh m√¥ h√¨nh ho·∫°t ƒë·ªông c·ª±c k·ª≥ ch√≠nh x√°c tr√™n t·∫≠p hu·∫•n luy·ªán.
2. Hi·ªáu su·∫•t tr√™n t·∫≠p ki·ªÉm tra
Test R¬≤: 0.9509

M√¥ h√¨nh gi·∫£i th√≠ch ƒë∆∞·ª£c 95.09% ph∆∞∆°ng sai tr√™n t·∫≠p ki·ªÉm tra, m·ªôt k·∫øt qu·∫£ r·∫•t cao.
D√π th·∫•p h∆°n t·∫≠p hu·∫•n luy·ªán, m·ª©c ƒë·ªô ch√™nh l·ªách nh·ªè, cho th·∫•y m√¥ h√¨nh t·ªïng qu√°t h√≥a t·ªët.
Test RMSE: 0.0894

Sai s·ªë trung b√¨nh tr√™n t·∫≠p ki·ªÉm tra l√† 0.0894 ƒë∆°n v·ªã, l·ªõn h∆°n t·∫≠p hu·∫•n luy·ªán nh∆∞ng v·∫´n ƒë·ªß nh·ªè ƒë·ªÉ kh·∫≥ng ƒë·ªãnh m√¥ h√¨nh d·ª± ƒëo√°n ch√≠nh x√°c.
3. Hi·ªáu su·∫•t v·ªõi ki·ªÉm tra ch√©o (Cross-Validation)
Cross-Validated R¬≤: 0.9642 ¬± 0.0177

M√¥ h√¨nh gi·∫£i th√≠ch ƒë∆∞·ª£c 96.42% ph∆∞∆°ng sai trung b√¨nh trong c√°c l·∫ßn ki·ªÉm tra ch√©o.
Sai s·ªë chu·∫©n (¬±0.0177) nh·ªè, ch·ª©ng t·ªè m√¥ h√¨nh ·ªïn ƒë·ªãnh tr√™n c√°c t·∫≠p d·ªØ li·ªáu kh√°c nhau.
Cross-Validated RMSE: 0.0716 ¬± 0.0247

Sai s·ªë trung b√¨nh tr√™n c√°c t·∫≠p ki·ªÉm tra trong ki·ªÉm tra ch√©o l√† 0.0716 ƒë∆°n v·ªã.
Sai s·ªë chu·∫©n (¬±0.0247) cho th·∫•y sai s·ªë kh√¥ng dao ƒë·ªông nhi·ªÅu gi·ªØa c√°c l·∫ßn ki·ªÉm tra, kh·∫≥ng ƒë·ªãnh s·ª± nh·∫•t qu√°n c·ªßa m√¥ h√¨nh.
T·ª´ ƒë√≥ cho th·∫•y ho·∫°t ƒë·ªông c·ªßa m√¥ h√¨nh th·∫≠t s·ª± hi·ªáu qu·∫£ v√† ch√∫ng em ƒë√£ ch·ª©ng minh ƒë∆∞·ª£c m√¥ h√¨nh kh√¥ng b·ªã overfitting.
"""

# Create a comparison dataframe
comparison_df = pd.DataFrame({
    "Metric": ["R¬≤", "RMSE", "MAE", "MAPE (%)"],
    "Train": [r2_train, rmse_train, mae_train, mape_train],
    "Test": [r2_test, rmse_test, mae_test, mape_test]
})

# Round the results
comparison_df = comparison_df.round(4)

# Display the dataframe
print(comparison_df)

"""Nh·∫≠n x√©t:


1. MAE (Train: 0.0106, Test: 0.0207):  Sai s·ªë trung b√¨nh tuy·ªát ƒë·ªëi tr√™n t·∫≠p ki·ªÉm tra g·∫•p ƒë√¥i t·∫≠p hu·∫•n luy·ªán nh∆∞ng v·∫´n r·∫•t th·∫•p, cho th·∫•y m√¥ h√¨nh ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh.
L√Ω do Sai s·ªë trung b√¨nh tuy·ªát ƒë·ªëi tr√™n t·∫≠p ki·ªÉm tra g·∫•p ƒë√¥i t·∫≠p hu·∫•n luy·ªán c√≥ th·ªÉ l√† do m·ª©c ƒë·ªô t·ªïng qu√°t h√≥a c·ªßa m√¥ h√¨nh ho·∫∑c ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ cao.
2. MAPE (Train: 20.64%, Test: 20.12%): Sai s·ªë t·ª∑ l·ªá ph·∫ßn trƒÉm trung b√¨nh tr√™n c·∫£ hai t·∫≠p g·∫ßn t∆∞∆°ng ƒë∆∞∆°ng, ch·ª©ng minh s·ª± ·ªïn ƒë·ªãnh c·ªßa m√¥ h√¨nh.
Qua ƒë√≥, v√¥ h√¨nh trung ch√∫ng ta c√≥ th·ªÉ m√¥ h√¨nh ho·∫°t ƒë·ªông r·∫•t t·ªët v√† ·ªïn ƒë·ªãnh.
"""

xgb_feature_importance = pd.DataFrame({
    "Feature": features,
    "Importance": xgb_model.feature_importances_
}).sort_values(by="Importance", ascending=False)

# Hi·ªÉn th·ªã t·∫ßm quan tr·ªçng
print(xgb_feature_importance)

plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual Momentum', color='blue')
plt.plot(y_pred_xgb, label='Predicted Momentum', color='orange')
plt.title("Actual vs Predicted Momentum")
plt.xlabel("Data Points")
plt.ylabel("Momentum_temp")
plt.legend()
plt.show()

xgb_feature_importance.plot(kind='bar', x='Feature', y='Importance', legend=False, figsize=(10, 6))
plt.title("Feature Importance (XGBoost)")
plt.xlabel("Features")
plt.ylabel("Importance Score")
plt.show()

"""Ch√∫ng em mu·ªën t·ªëi ∆∞u ƒë·ªÉ ƒë·∫°t t·ª∑ l·ªá cao h∆°n m·ªôt ch√∫t n·ªØa n√™n d√πng kƒ© thu·∫≠t Grid Search nh·∫Øm t·ªëi ∆∞u h√≥a c√°c tham s·ªë m√¥ h√¨nh v√† t√¨m ra m√¥ h√¨nh t·ªët nh·∫•t.

"""

# ƒê·ªãnh nghƒ©a l∆∞·ªõi tham s·ªë
param_grid = {
    'n_estimators': [100, 200, 300],       # S·ªë l∆∞·ª£ng c√¢y
    'max_depth': [3, 5, 7],               # ƒê·ªô s√¢u t·ªëi ƒëa
    'learning_rate': [0.01, 0.1, 0.2],    # T·ªëc ƒë·ªô h·ªçc
    'subsample': [0.8, 1.0],              # Ph·∫ßn trƒÉm m·∫´u s·ª≠ d·ª•ng
    'colsample_bytree': [0.8, 1.0],       # Ph·∫ßn trƒÉm ƒë·∫∑c tr∆∞ng s·ª≠ d·ª•ng
}

# Kh·ªüi t·∫°o m√¥ h√¨nh XGBoost
xgb_model = XGBRegressor(random_state=42)

# Thi·∫øt l·∫≠p GridSearchCV
grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    scoring='r2',         # T·ªëi ∆∞u h√≥a R¬≤
    cv=3,                 # S·ª≠ d·ª•ng 3-fold cross-validation
    verbose=1,
    n_jobs=-1             # S·ª≠ d·ª•ng to√†n b·ªô CPU
)

# Th·ª±c hi·ªán Grid Search
grid_search.fit(X_train, y_train)

# L·∫•y tham s·ªë t·ªët nh·∫•t v√† ƒëi·ªÉm s·ªë t·ªët nh·∫•t
best_params = grid_search.best_params_
best_score = grid_search.best_score_

# Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi tham s·ªë t·ªët nh·∫•t
best_xgb_model = grid_search.best_estimator_
y_pred_best_xgb = best_xgb_model.predict(X_test)

# ƒê√°nh gi√° m√¥ h√¨nh t·ªëi ∆∞u
optimized_r2 = r2_score(y_test, y_pred_best_xgb)
optimized_rmse = np.sqrt(mean_squared_error(y_test, y_pred_best_xgb))
mae_test = mean_absolute_error(y_test, y_pred_best_xgb)
mape_test = np.mean(np.abs((y_test - y_pred_best_xgb) / y_test)) * 100
print("Best Parameters:", best_params)
optimized_metrics = {
    "Metric": ["R¬≤", "RMSE", "MAE", "MAPE (%)"],
    "Value": [optimized_r2, optimized_rmse, mae_test, mape_test]
}

# T·∫°o DataFrame ƒë·ªÉ hi·ªÉn th·ªã
optimized_metrics_df = pd.DataFrame(optimized_metrics)
optimized_metrics_df = optimized_metrics_df.round(4)  # L√†m tr√≤n k·∫øt qu·∫£ ƒë·ªÉ d·ªÖ ƒë·ªçc

# Xu·∫•t k·∫øt qu·∫£
print(optimized_metrics_df)

"""Hi·ªáu su·∫•t t·ªïng th·ªÉ:

R¬≤ = 0.9606: M√¥ h√¨nh gi·∫£i th√≠ch ƒë∆∞·ª£c 96.06% ph∆∞∆°ng sai c·ªßa bi·∫øn m·ª•c ti√™u, cao h∆°n so v·ªõi phi√™n b·∫£n tr∆∞·ªõc (
R¬≤
=
0.9509
R
2
 =0.9509). ƒê√¢y l√† m·ªôt c·∫£i thi·ªán ƒë√°ng k·ªÉ v·ªÅ kh·∫£ nƒÉng d·ª± ƒëo√°n.
RMSE = 0.0801: Sai s·ªë trung b√¨nh gi·∫£m t·ª´ 0.0894 xu·ªëng 0.0801, cho th·∫•y ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh ƒë√£ tƒÉng.
ƒê·ªô ch√≠nh x√°c c·ª•c b·ªô:

MAE = 0.0206: Sai s·ªë tuy·ªát ƒë·ªëi trung b√¨nh gi·∫£m nh·∫π so v·ªõi phi√™n b·∫£n tr∆∞·ªõc (
ùëÄ
ùê¥
ùê∏
=
0.0207
MAE=0.0207), ch·ª©ng t·ªè m√¥ h√¨nh d·ª± ƒëo√°n ch√≠nh x√°c h∆°n cho t·ª´ng ƒëi·ªÉm d·ªØ li·ªáu.
MAPE = 25.6050%:

TƒÉng nh·∫π t·ª´ 20.1156% l√™n 25.6050%.
MAPE cao h∆°n cho th·∫•y m√¥ h√¨nh c√≥ th·ªÉ ch∆∞a t·ªët trong vi·ªác d·ª± ƒëo√°n c√°c gi√° tr·ªã nh·ªè ho·∫∑c c√°c ƒëi·ªÉm ngo·∫°i l·ªá.
"""

plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual Momentum', color='blue')
plt.plot(y_pred_best_xgb, label='Predicted Momentum', color='orange')
plt.title("Actual vs Predicted Momentum")
plt.xlabel("Data Points")
plt.ylabel("Momentum_temp")
plt.legend()
plt.show()

xgb_feature_importance.plot(kind='bar', x='Feature', y='Importance', legend=False, figsize=(10, 6))
plt.title("Feature Importance (XGBoost)")
plt.xlabel("Features")
plt.ylabel("Importance Score")
plt.show()

# Initialize a dictionary to store results for each match
match_results = {}

# Iterate over each unique match_id
for match_id in data['match_id'].unique():
    try:
        # Filter data for the current match
        match_data = data[data['match_id'] == match_id]

        # Check if there's enough data for training and testing
        if len(match_data) < 10:  # Arbitrary threshold to ensure enough data points
            print(f"Skipping match {match_id} due to insufficient data points.")
            continue

        # Extract features (X) and target (y)
        X_match = match_data[features] # Features from PCA
        y_match = match_data['Momentum_temp']        # Target variable

        # Split data into train and test sets
        X_train_match, X_test_match, y_train_match, y_test_match = train_test_split(
            X_match, y_match, test_size=0.2, random_state=42
        )

        # Train the model on the current match
        best_xgb_model.fit(X_train_match, y_train_match)

        # Predict on the test set
        y_pred_match = best_xgb_model.predict(X_test_match)

        # Evaluate performance
        r2_match = r2_score(y_test_match, y_pred_match)
        rmse_match = np.sqrt(mean_squared_error(y_test_match, y_pred_match))

        # Store the results
        match_results[match_id] = {
            'R¬≤': r2_match,
            'RMSE': rmse_match
        }
        print(f"Analyzed match: {match_id}, R¬≤: {r2_match:.4f}, RMSE: {rmse_match:.4f}")

    except Exception as e:
        # Handle any unexpected errors for a specific match
        print(f"Error processing match {match_id}: {e}")
        continue

# Convert the results dictionary to a DataFrame for easier analysis
match_results_df = pd.DataFrame.from_dict(match_results, orient='index')
match_results_df.index.name = 'Match_ID'

# Display the results

import matplotlib.pyplot as plt

# Extract data for plotting
match_ids = match_results_df.index  # Match IDs
r2_scores = match_results_df['R¬≤']  # R¬≤ values

# Plot R¬≤ values
plt.figure(figsize=(12, 6))
plt.bar(match_ids, r2_scores, color='skyblue', label='R¬≤ Scores')
plt.axhline(y=0.6, color='red', linestyle='--', label='Threshold: R¬≤ = 0.6')
plt.xticks(rotation=90)
plt.xlabel('Match ID')
plt.ylabel('R¬≤ Score')
plt.title('R¬≤ Scores for Each Match')
plt.legend()
plt.tight_layout()
plt.show()

"""H·∫ßu h·∫øt c√°c tr·∫≠n ƒë·∫•u ƒë·ªÅu c√≥ ch·ªâ s·ªë R¬≤ tr√™n 0.6, th·∫≠m ch√≠ r·∫•t nhi·ªÅu tr·∫≠n c√≤n >0.9 ch·ª©ng t·ªè m√¥ h√¨nh kh√¥ng ch·ªâ ho·∫°t ƒë·ªông t·ªët tr√™n t·ªïng th·ªÉ m√† c√≤n xu·∫•t s·∫Øc tr√™n t·ª´ng tr·∫≠n.
M·ªôt s·ªë tr·∫≠n v√≤i do s·ªë set trong 1 tr·∫≠n √≠t h∆°n d·∫´n ƒë·∫øn data train √≠t h∆°n n√™n ch·ªâ s·ªë n√†y th·∫•p h∆°n nh∆∞ng v·∫´n r·∫•t t·ªët.
"""

# Extract RMSE values
rmse_values = match_results_df['RMSE']  # RMSE values

# Plot RMSE values
plt.figure(figsize=(12, 6))
plt.bar(match_ids, rmse_values, color='orange', label='RMSE Values')
plt.axhline(y=1.5, color='green', linestyle='--', label='Threshold: RMSE = 1.5')
plt.xticks(rotation=90)
plt.xlabel('Match ID')
plt.ylabel('RMSE Value')
plt.title('RMSE Values for Each Match')
plt.legend()
plt.tight_layout()
plt.show()

"""RMSE c·ªßa h·∫ßu h·∫øt c√°c tr·∫≠n ƒë·∫•u th·∫•p (d∆∞·ªõi 1.5, ng∆∞·ª°ng ƒë√°nh gi√° t·ªët).
M·ªôt s·ªë tr·∫≠n ƒë·∫•u c√≥ RMSE cao h∆°n, c√≥ th·ªÉ l√† do l∆∞·ª£ng data cho t·ª´ng tr·∫≠n l√† kh√¥ng ƒë·ªÅu n√™n c√°c tr·∫≠n c√≥ s·ªë data √≠t h∆°n s·∫Ω c√≥ RMSE cao h∆°n nh∆∞ng kh√¥ng ƒë√°ng k·ªÉ. V√¥ h√¨nh trung ƒë√¢y c≈©ng l√† 1 m√¥ h√¨nh t·ªët.
"""

data['Predicted_Momentum'] = best_xgb_model.predict(data[features])
data.to_csv("predicted_momentum.csv", index=False)
print("File has been saved as predicted_momentum.csv")