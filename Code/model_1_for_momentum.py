# -*- coding: utf-8 -*-
"""Model_1_for_momentum.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/HuyenTrang457/MCM/blob/main/Model_1_for_momentum.ipynb
"""

!pip install factor_analyzer
!pip install statsmodels
!pip install pingouin
!pip install scipy
!pip install matplotlib
!pip uninstall -y scikit-learn
!pip install scikit-learn==1.3.1
!pip install xgboost pandas matplotlib seaborn scikit-learn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV
from xgboost import XGBRegressor
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Load the dataset
data = pd.read_csv("processed_tennis_data.csv")  # Replace with your file path

# Xem trước dữ liệu
print(data.head())

data['Log_Speed_mph'] = np.log1p(data['Speed_mph'])
data['Log_Speed_mph'] = data['Log_Speed_mph'].fillna(data['Speed_mph'].mean())
data['Interaction_Rally_Speed'] = data['Rally_count'] * data['Speed_mph']
features = [
    'Ace', 'Distance_run', 'Error_rate_of_serve_no.1', 'Rally_count',
    'Server_pt', 'Game_victor', 'Log_Speed_mph', 'Interaction_Rally_Speed'
]
print(data['Log_Speed_mph'] )

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Chuẩn hóa dữ liệu
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data[features])  # 'features' là danh sách các cột cần chuẩn hóa

# Áp dụng PCA
pca = PCA(n_components=len(features))  # Số thành phần chính = số lượng biến
pca.fit(scaled_data)

# Phương sai giải thích bởi từng thành phần chính
explained_variance_ratio = pca.explained_variance_ratio_

# Phương sai tích lũy
cumulative_variance = explained_variance_ratio.cumsum()

print("Explained Variance Ratio:", explained_variance_ratio)
print("Cumulative Variance:", cumulative_variance)

import matplotlib.pyplot as plt

# Vẽ biểu đồ
plt.figure(figsize=(10, 6))
plt.bar(range(1, len(features) + 1), explained_variance_ratio, alpha=0.7, label='Individual Variance')
plt.step(range(1, len(features) + 1), cumulative_variance, where='mid', label='Cumulative Variance', color='red')
plt.xlabel('Principal Components')
plt.ylabel('Variance Explained')
plt.title('Explained Variance by Principal Components')
plt.legend()
plt.grid()
plt.show()

# Hệ số tải (loadings)
loadings = pd.DataFrame(
    pca.components_.T,  # Ma trận hệ số tải từ PCA
    columns=[f'PC{i+1}' for i in range(len(features))],  # Tên các thành phần chính
    index=features  # Tên các biến gốc
)

# Tóm tắt phương sai
variance_summary = pd.DataFrame({
    'Principal Component': [f'PC{i+1}' for i in range(len(features))],
    'Explained Variance Ratio': explained_variance_ratio,
    'Cumulative Variance': cumulative_variance
})

# Hiển thị bảng loadings (PC1-PC3)
print("PCA Loadings (PC1-PC3):")
print(loadings.iloc[:, :3])  # Hiển thị chỉ 3 thành phần chính đầu tiên

# Hiển thị bảng phương sai
print("\nExplained Variance Summary:")
print(variance_summary)

"""Nhận xét từ biểu đồ và bảng hệ số tải (loadings)
PC1:
Rally_count (0.6749739) có ảnh hưởng mạnh nhất đến PC1 và có hệ số dương lớn nhất → PC1 đại diện cho yếu tố liên quan đến số lượt rally.
Interaction_Rally_Speed (-0.5123316) có hệ số âm lớn, cho thấy tốc độ tương tác rally tác động ngược chiều đến PC1.
PC2:
Ace (0.6220342) có ảnh hưởng mạnh nhất, tiếp theo là Log_Speed_mph (0.4596065) → PC2 có thể đại diện cho kỹ năng giao bóng và tốc độ.
PC3:
Distance_run (0.6272342) và Error_rate_of_serve_no.1 (-0.5837080) chi phối mạnh → PC3 đại diện cho yếu tố khoảng cách di chuyển và tỷ lệ lỗi giao bóng.
Explained Variance Ratio: Cho biết tỷ lệ phương sai được giải thích bởi từng thành phần chính.

PC1 (19.05%), PC2 (15.87%), và PC3 (15.23%) cùng giải thích 50.16% phương sai của dữ liệu → 3 thành phần chính giữ lại một nửa thông tin từ dữ liệu ban đầu.
Với 5 thành phần chính, tỷ lệ phương sai tích lũy đạt 77.80% → đủ để giữ lại phần lớn thông tin.
Cumulative Variance:

Sau PC6, phương sai tích lũy đạt 90.54%. Các thành phần từ PC7 trở đi đóng góp rất ít phương sai, nên có thể loại bỏ.

Tính Momentum_temp bằng cách mỗi thành phần chính được nhân với trọng số dựa trên Explained Variance Ratio.
![image.png](data:image/png;base64,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)
"""

weights = pca.explained_variance_ratio_[:6]  # Lấy trọng số cho 6 thành phần đầu
data['Momentum_temp'] = (pca.transform(scaled_data)[:, :6] * weights).sum(axis=1)

X = data[features]
y = data['Momentum_temp']

#chia tập huấn luyện
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Chọn model XGBost để train vì sao?
1. Quan hệ phi tuyến:
XGBoost rất mạnh trong việc phát hiện các mối quan hệ phi tuyến giữa các biến, điều mà các mô hình tuyến tính không làm được.
Hỗ trợ tương tác giữa các đặc trưng (features):
2. Bản chất của XGBoost là xây dựng các cây quyết định, giúp nắm bắt các tương tác giữa các biến mà không cần tính toán thủ công (feature engineering).
3. Rất hiệu quả với tập dữ liệu không quá lớn
"""

#Dùng model Xgbost để train mô hình
# Dự đoán trên tập kiểm tra
# Initialize XGBoost model
xgb_model = XGBRegressor(random_state=42, n_estimators=200, max_depth=5, learning_rate=0.1)

# Train the model
xgb_model.fit(X_train, y_train)
y_pred_test = xgb_model.predict(X_test)

# Tính các chỉ số trên tập kiểm tra
r2_test = r2_score(y_test, y_pred_test)
rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)

# So sánh với tập huấn luyện
y_pred_train = xgb_model.predict(X_train)
r2_train = r2_score(y_train, y_pred_train)
rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)
mae_test = mean_absolute_error(y_test, y_pred_test)
mape_test = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100
print(f"Train R²: {r2_train:.4f}, Train RMSE: {rmse_train:.4f}")
print(f"Test R²: {r2_test:.4f}, Test RMSE: {rmse_test:.4f}")

from sklearn.model_selection import cross_val_score

# Tính R² với Cross-Validation (5 folds)
cv_r2 = cross_val_score(xgb_model, X, y, cv=5, scoring='r2')
cv_rmse = -cross_val_score(xgb_model, X, y, cv=5, scoring='neg_root_mean_squared_error')

print(f"Cross-Validated R²: {cv_r2.mean():.4f} ± {cv_r2.std():.4f}")
print(f"Cross-Validated RMSE: {cv_rmse.mean():.4f} ± {cv_rmse.std():.4f}")

"""1. Hiệu suất trên tập huấn luyện
Train R²: 0.9976

Mô hình đã giải thích được 99.76% phương sai của biến mục tiêu (Momentum_temp) trên tập huấn luyện.
Đây là một giá trị rất cao, cho thấy mô hình đã học tốt trên tập huấn luyện.
Train RMSE: 0.0190

Sai số trung bình trên tập huấn luyện chỉ khoảng 0.019 đơn vị, rất nhỏ so với phạm vi dữ liệu.
Điều này khẳng định mô hình hoạt động cực kỳ chính xác trên tập huấn luyện.
2. Hiệu suất trên tập kiểm tra
Test R²: 0.9509

Mô hình giải thích được 95.09% phương sai trên tập kiểm tra, một kết quả rất cao.
Dù thấp hơn tập huấn luyện, mức độ chênh lệch nhỏ, cho thấy mô hình tổng quát hóa tốt.
Test RMSE: 0.0894

Sai số trung bình trên tập kiểm tra là 0.0894 đơn vị, lớn hơn tập huấn luyện nhưng vẫn đủ nhỏ để khẳng định mô hình dự đoán chính xác.
3. Hiệu suất với kiểm tra chéo (Cross-Validation)
Cross-Validated R²: 0.9642 ± 0.0177

Mô hình giải thích được 96.42% phương sai trung bình trong các lần kiểm tra chéo.
Sai số chuẩn (±0.0177) nhỏ, chứng tỏ mô hình ổn định trên các tập dữ liệu khác nhau.
Cross-Validated RMSE: 0.0716 ± 0.0247

Sai số trung bình trên các tập kiểm tra trong kiểm tra chéo là 0.0716 đơn vị.
Sai số chuẩn (±0.0247) cho thấy sai số không dao động nhiều giữa các lần kiểm tra, khẳng định sự nhất quán của mô hình.
Từ đó cho thấy hoạt động của mô hình thật sự hiệu quả và chúng em đã chứng minh được mô hình không bị overfitting.
"""

# Create a comparison dataframe
comparison_df = pd.DataFrame({
    "Metric": ["R²", "RMSE", "MAE", "MAPE (%)"],
    "Train": [r2_train, rmse_train, mae_train, mape_train],
    "Test": [r2_test, rmse_test, mae_test, mape_test]
})

# Round the results
comparison_df = comparison_df.round(4)

# Display the dataframe
print(comparison_df)

"""Nhận xét:


1. MAE (Train: 0.0106, Test: 0.0207):  Sai số trung bình tuyệt đối trên tập kiểm tra gấp đôi tập huấn luyện nhưng vẫn rất thấp, cho thấy mô hình hoạt động ổn định.
Lý do Sai số trung bình tuyệt đối trên tập kiểm tra gấp đôi tập huấn luyện có thể là do mức độ tổng quát hóa của mô hình hoặc độ chính xác tổng thể cao.
2. MAPE (Train: 20.64%, Test: 20.12%): Sai số tỷ lệ phần trăm trung bình trên cả hai tập gần tương đương, chứng minh sự ổn định của mô hình.
Qua đó, vô hình trung chúng ta có thể mô hình hoạt động rất tốt và ổn định.
"""

xgb_feature_importance = pd.DataFrame({
    "Feature": features,
    "Importance": xgb_model.feature_importances_
}).sort_values(by="Importance", ascending=False)

# Hiển thị tầm quan trọng
print(xgb_feature_importance)

plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual Momentum', color='blue')
plt.plot(y_pred_xgb, label='Predicted Momentum', color='orange')
plt.title("Actual vs Predicted Momentum")
plt.xlabel("Data Points")
plt.ylabel("Momentum_temp")
plt.legend()
plt.show()

xgb_feature_importance.plot(kind='bar', x='Feature', y='Importance', legend=False, figsize=(10, 6))
plt.title("Feature Importance (XGBoost)")
plt.xlabel("Features")
plt.ylabel("Importance Score")
plt.show()

"""Chúng em muốn tối ưu để đạt tỷ lệ cao hơn một chút nữa nên dùng kĩ thuật Grid Search nhắm tối ưu hóa các tham số mô hình và tìm ra mô hình tốt nhất.

"""

# Định nghĩa lưới tham số
param_grid = {
    'n_estimators': [100, 200, 300],       # Số lượng cây
    'max_depth': [3, 5, 7],               # Độ sâu tối đa
    'learning_rate': [0.01, 0.1, 0.2],    # Tốc độ học
    'subsample': [0.8, 1.0],              # Phần trăm mẫu sử dụng
    'colsample_bytree': [0.8, 1.0],       # Phần trăm đặc trưng sử dụng
}

# Khởi tạo mô hình XGBoost
xgb_model = XGBRegressor(random_state=42)

# Thiết lập GridSearchCV
grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    scoring='r2',         # Tối ưu hóa R²
    cv=3,                 # Sử dụng 3-fold cross-validation
    verbose=1,
    n_jobs=-1             # Sử dụng toàn bộ CPU
)

# Thực hiện Grid Search
grid_search.fit(X_train, y_train)

# Lấy tham số tốt nhất và điểm số tốt nhất
best_params = grid_search.best_params_
best_score = grid_search.best_score_

# Huấn luyện mô hình với tham số tốt nhất
best_xgb_model = grid_search.best_estimator_
y_pred_best_xgb = best_xgb_model.predict(X_test)

# Đánh giá mô hình tối ưu
optimized_r2 = r2_score(y_test, y_pred_best_xgb)
optimized_rmse = np.sqrt(mean_squared_error(y_test, y_pred_best_xgb))
mae_test = mean_absolute_error(y_test, y_pred_best_xgb)
mape_test = np.mean(np.abs((y_test - y_pred_best_xgb) / y_test)) * 100
print("Best Parameters:", best_params)
optimized_metrics = {
    "Metric": ["R²", "RMSE", "MAE", "MAPE (%)"],
    "Value": [optimized_r2, optimized_rmse, mae_test, mape_test]
}

# Tạo DataFrame để hiển thị
optimized_metrics_df = pd.DataFrame(optimized_metrics)
optimized_metrics_df = optimized_metrics_df.round(4)  # Làm tròn kết quả để dễ đọc

# Xuất kết quả
print(optimized_metrics_df)

"""Hiệu suất tổng thể:

R² = 0.9606: Mô hình giải thích được 96.06% phương sai của biến mục tiêu, cao hơn so với phiên bản trước (
R²
=
0.9509
R
2
 =0.9509). Đây là một cải thiện đáng kể về khả năng dự đoán.
RMSE = 0.0801: Sai số trung bình giảm từ 0.0894 xuống 0.0801, cho thấy độ chính xác của mô hình đã tăng.
Độ chính xác cục bộ:

MAE = 0.0206: Sai số tuyệt đối trung bình giảm nhẹ so với phiên bản trước (
𝑀
𝐴
𝐸
=
0.0207
MAE=0.0207), chứng tỏ mô hình dự đoán chính xác hơn cho từng điểm dữ liệu.
MAPE = 25.6050%:

Tăng nhẹ từ 20.1156% lên 25.6050%.
MAPE cao hơn cho thấy mô hình có thể chưa tốt trong việc dự đoán các giá trị nhỏ hoặc các điểm ngoại lệ.
"""

plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual Momentum', color='blue')
plt.plot(y_pred_best_xgb, label='Predicted Momentum', color='orange')
plt.title("Actual vs Predicted Momentum")
plt.xlabel("Data Points")
plt.ylabel("Momentum_temp")
plt.legend()
plt.show()

xgb_feature_importance.plot(kind='bar', x='Feature', y='Importance', legend=False, figsize=(10, 6))
plt.title("Feature Importance (XGBoost)")
plt.xlabel("Features")
plt.ylabel("Importance Score")
plt.show()

# Initialize a dictionary to store results for each match
match_results = {}

# Iterate over each unique match_id
for match_id in data['match_id'].unique():
    try:
        # Filter data for the current match
        match_data = data[data['match_id'] == match_id]

        # Check if there's enough data for training and testing
        if len(match_data) < 10:  # Arbitrary threshold to ensure enough data points
            print(f"Skipping match {match_id} due to insufficient data points.")
            continue

        # Extract features (X) and target (y)
        X_match = match_data[features] # Features from PCA
        y_match = match_data['Momentum_temp']        # Target variable

        # Split data into train and test sets
        X_train_match, X_test_match, y_train_match, y_test_match = train_test_split(
            X_match, y_match, test_size=0.2, random_state=42
        )

        # Train the model on the current match
        best_xgb_model.fit(X_train_match, y_train_match)

        # Predict on the test set
        y_pred_match = best_xgb_model.predict(X_test_match)

        # Evaluate performance
        r2_match = r2_score(y_test_match, y_pred_match)
        rmse_match = np.sqrt(mean_squared_error(y_test_match, y_pred_match))

        # Store the results
        match_results[match_id] = {
            'R²': r2_match,
            'RMSE': rmse_match
        }
        print(f"Analyzed match: {match_id}, R²: {r2_match:.4f}, RMSE: {rmse_match:.4f}")

    except Exception as e:
        # Handle any unexpected errors for a specific match
        print(f"Error processing match {match_id}: {e}")
        continue

# Convert the results dictionary to a DataFrame for easier analysis
match_results_df = pd.DataFrame.from_dict(match_results, orient='index')
match_results_df.index.name = 'Match_ID'

# Display the results

import matplotlib.pyplot as plt

# Extract data for plotting
match_ids = match_results_df.index  # Match IDs
r2_scores = match_results_df['R²']  # R² values

# Plot R² values
plt.figure(figsize=(12, 6))
plt.bar(match_ids, r2_scores, color='skyblue', label='R² Scores')
plt.axhline(y=0.6, color='red', linestyle='--', label='Threshold: R² = 0.6')
plt.xticks(rotation=90)
plt.xlabel('Match ID')
plt.ylabel('R² Score')
plt.title('R² Scores for Each Match')
plt.legend()
plt.tight_layout()
plt.show()

"""Hầu hết các trận đấu đều có chỉ số R² trên 0.6, thậm chí rất nhiều trận còn >0.9 chứng tỏ mô hình không chỉ hoạt động tốt trên tổng thể mà còn xuất sắc trên từng trận.
Một số trận vòi do số set trong 1 trận ít hơn dẫn đến data train ít hơn nên chỉ số này thấp hơn nhưng vẫn rất tốt.
"""

# Extract RMSE values
rmse_values = match_results_df['RMSE']  # RMSE values

# Plot RMSE values
plt.figure(figsize=(12, 6))
plt.bar(match_ids, rmse_values, color='orange', label='RMSE Values')
plt.axhline(y=1.5, color='green', linestyle='--', label='Threshold: RMSE = 1.5')
plt.xticks(rotation=90)
plt.xlabel('Match ID')
plt.ylabel('RMSE Value')
plt.title('RMSE Values for Each Match')
plt.legend()
plt.tight_layout()
plt.show()

"""RMSE của hầu hết các trận đấu thấp (dưới 1.5, ngưỡng đánh giá tốt).
Một số trận đấu có RMSE cao hơn, có thể là do lượng data cho từng trận là không đều nên các trận có số data ít hơn sẽ có RMSE cao hơn nhưng không đáng kể. Vô hình trung đây cũng là 1 mô hình tốt.
"""

data['Predicted_Momentum'] = best_xgb_model.predict(data[features])
data.to_csv("predicted_momentum.csv", index=False)
print("File has been saved as predicted_momentum.csv")