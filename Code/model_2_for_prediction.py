# -*- coding: utf-8 -*-
"""model_2_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/HuyenTrang457/MCM/blob/main/model_2_final.ipynb
"""

!pip uninstall -y scikit-learn
!pip install scikit-learn==1.3.1

!pip install catboost

"""ƒê·∫ßu ti√™n ta ti·∫øn h√†nh ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu ƒë·ªÉ xem c·∫ßn ch·ªçn m√¥ h√¨nh n√†o , c√≥ n√™n b·ªè tham s·ªë n√†o hay kh√¥ng v√† hi·ªÉu r√µ h∆°n v·ªÅ b·ªô d·ªØ li·ªáu m√¨nh c√≥."""

import os
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, log_loss
from scipy.stats import pointbiserialr, spearmanr
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import os
from scipy.stats import chi2_contingency
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.naive_bayes import GaussianNB
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, log_loss
import matplotlib.pyplot as plt
import pandas as pd
from tabulate import tabulate

# Load the processed dataset
data_path = "/content/dataForModel21 (1).csv"  # Replace with your actual processed data file path
data = pd.read_csv(data_path)

from scipy.stats import shapiro, kstest, norm

# Danh s√°ch c√°c bi·∫øn li√™n t·ª•c c·∫ßn ki·ªÉm tra
continuous_features = [
    'sets_diff', 'games_diff', 'score_diff', 'points_won_diff',
    'ace_diff',
    'p1_game_win_ratio', 'p1_set_win_ratio', 'distance_diff',
    'p1_point_win_ratio', 'p1_ace_ratio'

]
# K·∫øt qu·∫£ ki·ªÉm ƒë·ªãnh
results = []
for feature in continuous_features:
    data_sample = data[feature] # Lo·∫°i b·ªè gi√° tr·ªã NaN
    shapiro_stat, shapiro_p = shapiro(data_sample)
    ks_stat, ks_p = kstest(data_sample, 'norm', args=(data_sample.mean(), data_sample.std()))

    results.append({
        'Feature': feature,
        'Shapiro-Wilk p-value': shapiro_p,
        'Kolmogorov-Smirnov p-value': ks_p
    })

# Chuy·ªÉn th√†nh DataFrame ƒë·ªÉ hi·ªÉn th·ªã
import pandas as pd
results_df = pd.DataFrame(results)
print(results_df)

"""D·ª±a tr√™n gi√° tr·ªã p-value t·ª´ Shapiro-Wilk v√† Kolmogorov-Smirnov:

p-value < 0.05 cho t·∫•t c·∫£ c√°c bi·∫øn ‚Üí D·ªØ li·ªáu kh√¥ng tu√¢n theo ph√¢n ph·ªëi chu·∫©n.
ƒêi·ªÅu n√†y c√≥ nghƒ©a r·∫±ng ta kh√¥ng th·ªÉ gi·∫£ ƒë·ªãnh c√°c bi·∫øn li√™n t·ª•c n√†y c√≥ ph√¢n ph·ªëi chu·∫©n. K·∫øt qu·∫£ √°p d·ª•ng cho c·∫£ c√°c bi·∫øn ch√™nh l·ªách (sets_diff, games_diff, score_diff, ...) v√† c√°c bi·∫øn t·ª∑ l·ªá (p1_game_win_ratio, p1_point_win_ratio, ...).

"""

from scipy.stats import ttest_ind, mannwhitneyu
from scipy.stats import mannwhitneyu, kruskal, friedmanchisquare
import pandas as pd

# L·ªçc d·ªØ li·ªáu theo nh√≥m m·ª•c ti√™u
group1 = data[data['point_victor_p1'] == 1]
group0 = data[data['point_victor_p1'] == 0]

# Danh s√°ch c√°c bi·∫øn li√™n t·ª•c c·∫ßn ki·ªÉm tra
continuous_features = [
    'sets_diff', 'games_diff', 'score_diff', 'points_won_diff',
    'ace_diff',
    'p1_game_win_ratio', 'p1_set_win_ratio', 'distance_diff',
    'p1_point_win_ratio', 'p1_ace_ratio'

]

# Mann-Whitney U-test
results = []
for feature in continuous_features:
    # Mann-Whitney U Test (Two groups, independent)
    mw_stat, mw_pval = mannwhitneyu(group1[feature], group0[feature], alternative='two-sided', nan_policy='omit')
    def permutation_test(data1, data2, n_resamples=10000):
        combined = np.concatenate([data1, data2])
        observed_diff = np.mean(data1) - np.mean(data2)

        resampled_diffs = []
        for _ in range(n_resamples):
            np.random.shuffle(combined)
            resampled1 = combined[:len(data1)]
            resampled2 = combined[len(data1):]
            resampled_diffs.append(np.mean(resampled1) - np.mean(resampled2))

        p_value = (np.sum(np.abs(resampled_diffs) >= np.abs(observed_diff)) + 1) / (n_resamples + 1)
        return p_value

    permutation_pval = permutation_test(group1[feature], group0[feature])

    results.append({
        'Feature': feature,
        'Mann-Whitney U p-value': mw_pval,
        'Permutation p-value': permutation_pval
    })


# K·∫øt qu·∫£ d∆∞·ªõi d·∫°ng DataFrame
results_df = pd.DataFrame(results)
print(results_df)

"""ƒê·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t (r·∫•t nh·ªè p-value):

score_diff, points_won_diff, ace_diff, distance_diff, p1_point_win_ratio, v√† p1_ace_ratio ƒë·ªÅu c√≥ gi√° tr·ªã p-value r·∫•t nh·ªè (d∆∞·ªõi
10^-30
  v·ªõi Mann-Whitney U p-value v√† g·∫ßn b·∫±ng 0 v·ªõi Permutation p-value).
ƒêi·ªÅu n√†y cho th·∫•y c√°c ƒë·∫∑c tr∆∞ng n√†y c√≥ √Ω nghƒ©a th·ªëng k√™ r·∫•t cao trong vi·ªác ph√¢n bi·ªát ho·∫∑c d·ª± ƒëo√°n.
ƒê·∫∑c tr∆∞ng √≠t quan tr·ªçng h∆°n:

sets_diff v√† p1_set_win_ratio c√≥ p-value cao h∆°n, l·∫ßn l∆∞·ª£t l√† 0.0658 v√† 0.0210 v·ªõi Mann-Whitney U, g·∫ßn v·ªõi m·ª©c √Ω nghƒ©a 0.05, cho th·∫•y ch√∫ng √≠t quan tr·ªçng h∆°n so v·ªõi c√°c ƒë·∫∑c tr∆∞ng kh√°c.
S·ª± nh·∫•t qu√°n c·ªßa p-value:

Permutation p-value cho th·∫•y t·∫•t c·∫£ c√°c ƒë·∫∑c tr∆∞ng ƒë·ªÅu c√≥ m·ª©c √Ω nghƒ©a th·ªëng k√™ cao (<= 0.05), nh∆∞ng m·ªôt s·ªë ƒë·∫∑c tr∆∞ng nh∆∞ sets_diff c√≥ gi√° tr·ªã p-value g·∫ßn m·ª©c gi·ªõi h·∫°n √Ω nghƒ©a.
·ª®ng d·ª•ng th·ª±c ti·ªÖn:

C√°c ƒë·∫∑c tr∆∞ng v·ªõi p-value th·∫•p (v√≠ d·ª•: score_diff, ace_diff, p1_point_win_ratio) n√™n ƒë∆∞·ª£c ∆∞u ti√™n s·ª≠ d·ª•ng trong c√°c m√¥ h√¨nh d·ª± ƒëo√°n ho·∫∑c ph√¢n t√≠ch s√¢u h∆°n v√¨ ch√∫ng c√≥ √Ω nghƒ©a ph√¢n bi·ªát m·∫°nh m·∫Ω.
C√°c ƒë·∫∑c tr∆∞ng nh∆∞ sets_diff c√≥ th·ªÉ c·∫ßn xem x√©t l·∫°i ho·∫∑c c√≥ th·ªÉ k√©m hi·ªáu qu·∫£ h∆°n trong vi·ªác d·ª± ƒëo√°n.

K·∫øt qu·∫£
ùëù
-value
=
1.000
p-value=1.000 cho th·∫•y kh√¥ng c√≥ b·∫•t k·ª≥ s·ª± kh√°c bi·ªát n√†o v·ªÅ t·∫ßn su·∫•t c·ªßa c√°c gi√° tr·ªã serve_width, serve_depth, return_depth gi·ªØa hai nh√≥m (th·∫Øng/thua ƒëi·ªÉm).
ƒêi·ªÅu n√†y nghƒ©a l√† c√°c chi·∫øn thu·∫≠t giao/tr·∫£ b√≥ng kh√¥ng ph·∫£i l√† y·∫øu t·ªë quy·∫øt ƒë·ªãnh tr·ª±c ti·∫øp ƒë·∫øn vi·ªác th·∫Øng ƒëi·ªÉm trong t·∫≠p d·ªØ li·ªáu hi·ªán t·∫°i.
double_fault_diff l√† ch√™nh l·ªách s·ªë l·∫ßn giao b√≥ng l·ªói k√©p gi·ªØa hai ng∆∞·ªùi ch∆°i.
ùëù
-value
=
1.000
p-value=1.000 cho th·∫•y bi·∫øn n√†y kh√¥ng ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ ƒë·∫øn k·∫øt qu·∫£ th·∫Øng ƒëi·ªÉm.

T·∫°i sao:
C√≥ th·ªÉ v√¨ l·ªói k√©p kh√¥ng x·∫£y ra th∆∞·ªùng xuy√™n trong d·ªØ li·ªáu, d·∫´n ƒë·∫øn thi·∫øu s·ª± kh√°c bi·ªát th·ªëng k√™.

Ho·∫∑c ch√™nh l·ªách l·ªói k√©p gi·ªØa hai ng∆∞·ªùi ch∆°i kh√¥ng ƒë·ªß l·ªõn ƒë·ªÉ t√°c ƒë·ªông ƒë√°ng k·ªÉ ƒë·∫øn x√°c su·∫•t th·∫Øng

p-value=1.545306√ó10
‚àí238
  ch·ªâ ra m·ªëi li√™n h·ªá r·∫•t m·∫°nh gi·ªØa vi·ªác ng∆∞·ªùi giao b√≥ng l√† player1 v√† x√°c su·∫•t th·∫Øng ƒëi·ªÉm.
Nghƒ©a l√† ng∆∞·ªùi giao b√≥ng (server_is_p1) c√≥ kh·∫£ nƒÉng ·∫£nh h∆∞·ªüng l·ªõn ƒë·∫øn k·∫øt qu·∫£ th·∫Øng ƒëi·ªÉm.

Trong tennis, ng∆∞·ªùi giao b√≥ng th∆∞·ªùng c√≥ l·ª£i th·∫ø nh·ªù ki·ªÉm so√°t ƒëi·ªÉm b·∫Øt ƒë·∫ßu, t·ªëc ƒë·ªô b√≥ng, v√† kh·∫£ nƒÉng ace. ƒêi·ªÅu n√†y l√† r·∫•t ph√π h·ª£p v·ªõi th·ª±c t·∫ø n√™n m·ªôt l·∫ßn n·ªØa cho th·∫•y ƒë·ªô ƒë√°ng tin c·∫≠y c·ªßa ki·ªÉm ƒë·ªãnh n√†y v·ªõi c√°c bi·∫øn.

p-value=0.144 kh√¥ng ƒë·ªß nh·ªè ƒë·ªÉ kh·∫≥ng ƒë·ªãnh m·ªëi li√™n h·ªá gi·ªØa c√∫ giao b√≥ng th·ª© nh·∫•t (first_serve) v√† bi·∫øn m·ª•c ti√™u (th·∫Øng/thua ƒëi·ªÉm).

C√≥ th·ªÉ c√∫ giao b√≥ng th·ª© nh·∫•t kh√¥ng lu√¥n mang l·∫°i l·ª£i th·∫ø, ho·∫∑c bi·∫øn n√†y kh√¥ng ƒë·ªß ƒë·ªôc l·∫≠p ƒë·ªÉ gi·∫£i th√≠ch kh√°c bi·ªát v√¨ n√≥ c√≥ 1 ph·∫ßn ph·ª• thu·ªôc v√†o server_is_p1 ho·∫∑c do t·∫ßn su·∫•t kh√¥ng qu√° nhi·ªÅu tr√™n to√†n b·ªô t·∫≠p
"""

# T√≠nh ma tr·∫≠n t∆∞∆°ng quan
correlation_matrix = data[continuous_features].corr(method='pearson')  # Ho·∫∑c 'spearman'

# V·∫Ω heatmap ƒë·ªÉ tr·ª±c quan h√≥a
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.title('Correlation Matrix of Continuous Features')
plt.show()
strong_positive_corr = []
strong_negative_corr = []

for i in range(len(correlation_matrix)):
    for j in range(i + 1, len(correlation_matrix)):
        corr_value = correlation_matrix.iloc[i, j]
        if corr_value > 0.7:
            strong_positive_corr.append((correlation_matrix.index[i], correlation_matrix.columns[j], corr_value))
        elif corr_value < -0.7:
            strong_negative_corr.append((correlation_matrix.index[i], correlation_matrix.columns[j], corr_value))

print("Strong positive correlations (> 0.7):")
for pair in strong_positive_corr:
    print(pair)

print("\nStrong negative correlations (< -0.7):")
for pair in strong_negative_corr:
    print(pair)

"""

V√¨ c√°c bi·ªÉn c√≥ t∆∞∆°ng quan > 0.7 c√≥ ƒë·ªô ph·ª• thu·ªôc v√†o nhau r·∫•t l·ªõn v√¨ th·∫ø ƒë·ªÉ gi·∫£m chi·ªÅu d·ªØ li·ªáu, tr√°nh ƒëa c·ªông tuy·∫øn, ƒë·ªìng th·ªùi l√†m m√¥ h√¨nh ƒë∆°n gi·∫£n h∆°n. V√¨ th·∫ø lo·∫°i b·ªè 1 v√†i bi·∫øn sets_diff, ace_diff, 'p1_set_win_ratio'"""

continuous_features = [
    'games_diff', 'score_diff', 'points_won_diff',
    'p1_game_win_ratio', 'distance_diff',
    'p1_point_win_ratio', 'p1_ace_ratio'

]

# Danh s√°ch c√°c bi·∫øn nh·ªã ph√¢n/danh m·ª•c
categorical_features = [ 'serve_width', 'serve_depth', 'return_depth', 'double_fault_diff', 'server_is_p1','first_serve',]

# Chi-square test
chi2_results = []
for feature in categorical_features:
    contingency_table = pd.crosstab(data[feature], data['point_victor_p1'])
    chi2_stat, chi2_pval, _, _ = chi2_contingency(contingency_table)
    chi2_results.append({
        'Feature': feature,
        'Chi-square p-value': chi2_pval
    })

# K·∫øt qu·∫£
chi2_df = pd.DataFrame(chi2_results)
print(chi2_df)

import pandas as pd
from statsmodels.stats.outliers_influence import variance_inflation_factor

# V√≠ d·ª•: Ch·ªçn c√°c c·ªôt li√™n quan (thay b·∫±ng c√°c c·ªôt c·ªßa b·∫°n)

# T·∫°o m·ªôt DataFrame ch·ªâ ch·ª©a c√°c bi·∫øn ƒë·ªôc l·∫≠p
X = data[continuous_features]

# Th√™m m·ªôt c·ªôt h·∫±ng s·ªë (c·∫ßn thi·∫øt ƒë·ªÉ t√≠nh VIF)
X = X.assign(const=1)

# T√≠nh to√°n VIF cho t·ª´ng bi·∫øn
vif_data = pd.DataFrame()
vif_data["Variable"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]


# Hi·ªÉn th·ªã k·∫øt qu·∫£
print(vif_data)

# T·∫°o DataFrame k·∫øt h·ª£p
data_train = pd.concat(
    [data[continuous_features], data[categorical_features], data['point_victor_p1']],
    axis=1
)

from sklearn.model_selection import train_test_split
X = data_train.drop(columns=['point_victor_p1'])  # Bi·∫øn ƒë·ªôc l·∫≠p
y = data_train['point_victor_p1']  # Bi·∫øn m·ª•c ti√™u

# Chia d·ªØ li·ªáu th√†nh Train (60%), Validation (10%), Test (10%)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.6, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

"""Th√≠ Nghi·ªám 1 :gi·ªØ nguy√™n c√°c categorical_features kh√¥ng c√≥ √Ω nghƒ©a th·ªëng k√™"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
from tabulate import tabulate
import pandas as pd

# L∆∞u k·∫øt qu·∫£
results = []

# Danh s√°ch m√¥ h√¨nh
models = {
    "LGBM": LGBMClassifier(n_estimators=10, max_depth=10, random_state=42),
    "XGBoost": XGBClassifier(n_estimators=10, max_depth=10, learning_rate=0.1, random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "MLP": MLPClassifier(hidden_layer_sizes=(64, 32), random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42),
    "Extra Trees": ExtraTreesClassifier(n_estimators=10, random_state=42),
    "CatBoost": CatBoostClassifier(iterations=10, depth=10, learning_rate=0.1, verbose=0, random_state=42),
    "Naive Bayes": GaussianNB()
}

# Hu·∫•n luy·ªán v√† ƒë√°nh gi√° t·ª´ng m√¥ h√¨nh
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    accuracy = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None
    logloss = log_loss(y_test, y_prob) if y_prob is not None else None
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results.append({
        "Model": name,
        "Accuracy": accuracy,
        "AUC": auc,
        "Log Loss": logloss,
        "Precision": precision,
        "Recall": recall,
        "F1": f1
    })

# Chuy·ªÉn k·∫øt qu·∫£ th√†nh DataFrame
results_df = pd.DataFrame(results)

# ƒê·ªãnh d·∫°ng b·∫£ng
results_table = tabulate(results_df, headers="keys", tablefmt="grid")

# Hi·ªÉn th·ªã b·∫£ng
print(results_table)

"""Th√≠ nghi·ªám 2 : lo·∫°i b·ªè c√°c categorical_features kh√¥ng c√≥ √Ω nghƒ©a th·ªëng k√™"""

categorical_features = [ 'server_is_p1']

# T·∫°o DataFrame k·∫øt h·ª£p
data_train = pd.concat(
    [data[continuous_features], data[categorical_features], data['point_victor_p1']],
    axis=1
)



from sklearn.model_selection import train_test_split
X = data_train.drop(columns=['point_victor_p1'])  # Bi·∫øn ƒë·ªôc l·∫≠p
y = data_train['point_victor_p1']  # Bi·∫øn m·ª•c ti√™u

# Chia d·ªØ li·ªáu th√†nh Train (60%), Validation (10%), Test (10%)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.6, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
from tabulate import tabulate
import pandas as pd

# L∆∞u k·∫øt qu·∫£
results1 = []

# Danh s√°ch m√¥ h√¨nh
models = {
    "LGBM": LGBMClassifier(n_estimators=10, max_depth=10, random_state=42),
    "XGBoost": XGBClassifier(n_estimators=10, max_depth=10, learning_rate=0.1, random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "MLP": MLPClassifier(hidden_layer_sizes=(64, 32), random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42),
    "Extra Trees": ExtraTreesClassifier(n_estimators=10, random_state=42),
    "CatBoost": CatBoostClassifier(iterations=10, depth=10, learning_rate=0.1, verbose=0, random_state=42),
    "Naive Bayes": GaussianNB()
}

# Hu·∫•n luy·ªán v√† ƒë√°nh gi√° t·ª´ng m√¥ h√¨nh
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    accuracy = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None
    logloss = log_loss(y_test, y_prob) if y_prob is not None else None
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results1.append({
        "Model": name,
        "Accuracy": accuracy,
        "AUC": auc,
        "Log Loss": logloss,
        "Precision": precision,
        "Recall": recall,
        "F1": f1
    })

# Chuy·ªÉn k·∫øt qu·∫£ th√†nh DataFrame
results_df = pd.DataFrame(results1)

# ƒê·ªãnh d·∫°ng b·∫£ng
results_table = tabulate(results_df, headers="keys", tablefmt="grid")

# Hi·ªÉn th·ªã b·∫£ng
print(results_table)

"""T·ª´ ƒë√≥ cho th·∫•y c√°c th√¥ng s·ªë kia tuy ki·ªÉm ƒë·ªãnh c√≥ ch·ªâ s·ªë kh√¥ng ·∫•n t∆∞·ª£ng nh∆∞ng l·∫°i ƒë√≥ng g√≥p ƒë√°ng k·ªÉ cho hi·ªáu su·∫•t m√¥ h√¨nh v√¨ v·∫≠y ti·∫øp d∆∞·ªõi ƒë√¢y t√¥i s·∫Ω d√πng th√≠ nghi·ªám 1 ƒë·ªÉ ti·∫øp t·ª•c th√≠ nghi·ªám 3

Th√≠ nghi·ªám 3: Chuy·ªán g√¨ x·∫£y ra n·∫øu th√™m momentum_temp t·ª´ model v√†o model d·ª± ƒëo√°n? Li·ªáu n√≥ t√°c ƒë·ªông nh∆∞ th·∫ø n√†o?
"""

data2 = pd.read_csv('/content/predicted_momentum (1).csv')  # File ch·ª©a Momentum_temp
print(data2)

categorical_features = [ 'serve_width', 'serve_depth', 'return_depth', 'double_fault_diff', 'server_is_p1','first_serve',]

data_train['Momentum_temp'] = data2['Momentum_temp']

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
from tabulate import tabulate
import pandas as pd

# L∆∞u k·∫øt qu·∫£
results3 = []

# Danh s√°ch m√¥ h√¨nh
models = {
    "LGBM": LGBMClassifier(n_estimators=10, max_depth=10, random_state=42),
    "XGBoost": XGBClassifier(n_estimators=10, max_depth=10, learning_rate=0.1, random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "MLP": MLPClassifier(hidden_layer_sizes=(64, 32), random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42),
    "Extra Trees": ExtraTreesClassifier(n_estimators=10, random_state=42),
    "CatBoost": CatBoostClassifier(iterations=10, depth=10, learning_rate=0.1, verbose=0, random_state=42),
    "Naive Bayes": GaussianNB()
}

# Hu·∫•n luy·ªán v√† ƒë√°nh gi√° t·ª´ng m√¥ h√¨nh
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    accuracy = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None
    logloss = log_loss(y_test, y_prob) if y_prob is not None else None
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results3.append({
        "Model": name,
        "Accuracy": accuracy,
        "AUC": auc,
        "Log Loss": logloss,
        "Precision": precision,
        "Recall": recall,
        "F1": f1
    })

# Chuy·ªÉn k·∫øt qu·∫£ th√†nh DataFrame
results_df = pd.DataFrame(results3)

# ƒê·ªãnh d·∫°ng b·∫£ng
results_table = tabulate(results_df, headers="keys", tablefmt="grid")

# Hi·ªÉn th·ªã b·∫£ng
print(results_table)

"""Qua ƒë√≥, ta r√∫t ra ƒë∆∞·ª£c 2 k·∫øt lu·∫≠n

1. Ta th·∫•y ƒë∆∞·ª£c r·∫±ng khi cho bi·∫øn momentum v√†o r√µ r√†ng t√°c ƒë·ªông ƒë√°ng k·ªÉ ƒë·ªÉ m√¥ h√¨nh cho th·∫•y momentum ƒë√≥ng vai tr√≤ quan tr·ªçng v√† c√≥ √Ω nghƒ©a trong m·ªôt tr·∫≠n ƒë·∫•u.

2. 3 m√¥ h√¨nh hi·ªáu qu·∫£ nh·∫•t l√† LGBM,XGBoost,RandomForest.
v√¨ th·∫ø ƒë·ªÉ t·∫°o m√¥ h√¨nh t·ªïng h·ª£p d·ª± ƒëo√°n x√°c su·∫•t chi·∫øn th·∫Øng c·ªßa ng∆∞·ªùi ch∆°i qua t·ª´ng point th√¨ ch√∫ng t√¥i ban ƒë·∫ßu t·ªëi ∆∞u h√≥a t·ª´ng model ri√™ng ƒë·ªÉ ki·∫øm tham s·ªë t·ªëi ∆∞u , sau ƒë√≥ ch√∫ng t√¥i k·∫øt h∆°p l·∫°i th√†nh emsable model nh·∫±m c·∫£i thi·ªán hi·ªáu qu·∫£
"""

from sklearn.model_selection import GridSearchCV
from lightgbm import LGBMClassifier

# ƒê·ªãnh nghƒ©a tham s·ªë c·∫ßn t·ªëi ∆∞u
param_grid_lgbm = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'learning_rate': [0.01, 0.1, 0.2],
    'num_leaves': [31, 50, 70]
}

# Kh·ªüi t·∫°o GridSearch
lgbm_model = LGBMClassifier(random_state=42)
grid_lgbm = GridSearchCV(lgbm_model, param_grid_lgbm, scoring='roc_auc', cv=3, verbose=1, n_jobs=-1)
grid_lgbm.fit(X_train, y_train)

# K·∫øt qu·∫£ t·ªët nh·∫•t
print("Best parameters for LightGBM:", grid_lgbm.best_params_)
print("Best AUC for LightGBM:", grid_lgbm.best_score_)

# L∆∞u m√¥ h√¨nh t·ªët nh·∫•t
best_lgbm = grid_lgbm.best_estimator_

from xgboost import XGBClassifier

# ƒê·ªãnh nghƒ©a tham s·ªë c·∫ßn t·ªëi ∆∞u
param_grid_xgb = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

# Kh·ªüi t·∫°o GridSearch
xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
grid_xgb = GridSearchCV(xgb_model, param_grid_xgb, scoring='roc_auc', cv=3, verbose=1, n_jobs=-1)
grid_xgb.fit(X_train, y_train)

# K·∫øt qu·∫£ t·ªët nh·∫•t
print("Best parameters for XGBoost:", grid_xgb.best_params_)
print("Best AUC for XGBoost:", grid_xgb.best_score_)

# L∆∞u m√¥ h√¨nh t·ªët nh·∫•t
best_xgb = grid_xgb.best_estimator_

from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss
from tabulate import tabulate
import pandas as pd

# K·∫øt h·ª£p c√°c m√¥ h√¨nh t·ªët nh·∫•t
ensemble_model = VotingClassifier(
    estimators=[
        ('LGBM', best_lgbm),
        ('XGBoost', best_xgb),
        ('RandomForest', RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42))
    ],
    voting='soft'  # L·∫•y x√°c su·∫•t d·ª± ƒëo√°n (soft voting)
)

# Hu·∫•n luy·ªán VotingClassifier
ensemble_model.fit(X_train, y_train)

# D·ª± ƒëo√°n v√† ƒë√°nh gi√°

y_val_pred_ensemble = ensemble_model.predict(X_val)
y_val_prob_ensemble = ensemble_model.predict_proba(X_val)[:, 1]

# T√≠nh to√°n c√°c ch·ªâ s·ªë cho Ensemble
ensemble_accuracy = accuracy_score(y_val, y_val_pred_ensemble)
ensemble_auc = roc_auc_score(y_val, y_val_prob_ensemble)
ensemble_logloss = log_loss(y_val, y_val_prob_ensemble)
ensemble_precision = precision_score(y_val, y_val_pred_ensemble)
ensemble_recall = recall_score(y_val, y_val_pred_ensemble)
ensemble_f1 = f1_score(y_val, y_val_pred_ensemble)
results1 = []
# L∆∞u k·∫øt qu·∫£ m√¥ h√¨nh Ensemble
ensemble_result = {
    "Model": "Ensemble Voting",
    "Accuracy": ensemble_accuracy,
    "AUC": ensemble_auc,
    "Log Loss": ensemble_logloss,
    "Precision": ensemble_precision,
    "Recall": ensemble_recall,
    "F1": ensemble_f1
}

# Th√™m v√†o b·∫£ng k·∫øt qu·∫£
results1.append(ensemble_result)

# Chuy·ªÉn k·∫øt qu·∫£ th√†nh DataFrame
results_df = pd.DataFrame(results1)

# ƒê·ªãnh d·∫°ng b·∫£ng
results_table = tabulate(results_df, headers="keys", tablefmt="grid")

# Hi·ªÉn th·ªã b·∫£ng
print(results_table)

# Tr√≠ch xu·∫•t feature importance t·ª´ c√°c m√¥ h√¨nh th√†nh ph·∫ßn
feature_importances = {}

# 1. Tr√≠ch xu·∫•t t·ª´ LightGBM
if 'LGBM' in dict(ensemble_model.named_estimators_):
    lgbm_model = ensemble_model.named_estimators_['LGBM']
    feature_importances['LGBM'] = lgbm_model.feature_importances_

# 2. Tr√≠ch xu·∫•t t·ª´ XGBoost
if 'XGBoost' in dict(ensemble_model.named_estimators_):
    xgb_model = ensemble_model.named_estimators_['XGBoost']
    feature_importances['XGBoost'] = xgb_model.feature_importances_

# 3. Tr√≠ch xu·∫•t t·ª´ Random Forest
if 'RandomForest' in dict(ensemble_model.named_estimators_):
    rf_model = ensemble_model.named_estimators_['RandomForest']
    feature_importances['RandomForest'] = rf_model.feature_importances_

# T·ªïng h·ª£p feature importance
average_importance = np.mean(
    [feature_importances[model] for model in feature_importances], axis=0
)

# Chuy·ªÉn th√†nh DataFrame ƒë·ªÉ tr·ª±c quan h√≥a
importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Average Importance': average_importance
}).sort_values(by='Average Importance', ascending=False)

# Hi·ªÉn th·ªã Top 10 ƒë·∫∑c tr∆∞ng quan tr·ªçng
print("Top 10 Most Important Features:")
print(importance_df.head(10))

# Tr·ª±c quan h√≥a
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'][:10], importance_df['Average Importance'][:10], color='skyblue')
plt.xlabel("Average Feature Importance")
plt.ylabel("Feature")
plt.title("Top 10 Feature Importance from VotingClassifier")
plt.gca().invert_yaxis()  # ƒê·∫£o ng∆∞·ª£c tr·ª•c y
plt.show()

"""1. distance_diff (S·ª± kh√°c bi·ªát kho·∫£ng c√°ch):
√ù nghƒ©a: Ph·∫£n √°nh kh·∫£ nƒÉng di chuy·ªÉn v√† ki·ªÉm so√°t s√¢n ƒë·∫•u. Di chuy·ªÉn hi·ªáu qu·∫£ gi√∫p ti·∫øt ki·ªám nƒÉng l∆∞·ª£ng v√† ki·ªÉm so√°t tr·∫≠n ƒë·∫•u.
Chi·∫øn l∆∞·ª£c:
C·∫£i thi·ªán kh·∫£ nƒÉng di chuy·ªÉn ngang v√† gi·ªØ v·ªã tr√≠ trung t√¢m s√¢n.
Hu·∫•n luy·ªán chi·∫øn thu·∫≠t √©p ƒë·ªëi th·ªß di chuy·ªÉn nhi·ªÅu h∆°n ƒë·ªÉ t·∫°o √°p l·ª±c.
2. p1_point_win_ratio (T·ª∑ l·ªá ƒëi·ªÉm th·∫Øng):
√ù nghƒ©a: Hi·ªáu su·∫•t t·ªïng th·ªÉ, ph·∫£n √°nh kh·∫£ nƒÉng t·∫≠n d·ª•ng c∆° h·ªôi v√† ghi ƒëi·ªÉm trong c√°c t√¨nh hu·ªëng quan tr·ªçng.
Chi·∫øn l∆∞·ª£c:
Luy·ªán kh·∫£ nƒÉng k·∫øt th√∫c ƒëi·ªÉm t·ª´ c√∫ ƒë√°nh thu·∫≠n tay, volley.
Ph√°t tri·ªÉn chi·∫øn thu·∫≠t t√¢m l√Ω cho c√°c ƒëi·ªÉm s·ªë quan tr·ªçng (break point, set point).
3. score_diff v√† points_won_diff:
√ù nghƒ©a: Th·ªÉ hi·ªán kh·∫£ nƒÉng duy tr√¨ l·ª£i th·∫ø v√† ki·ªÉm so√°t ƒëi·ªÉm s·ªë trong tr·∫≠n ƒë·∫•u.
Chi·∫øn l∆∞·ª£c:
Ph√¢n t√≠ch c√°c set ƒë·∫•u thua ƒë·ªÉ c·∫£i thi·ªán chi·∫øn thu·∫≠t.
T·∫≠p trung duy tr√¨ nh·ªãp ch∆°i ·ªïn ƒë·ªãnh v√† luy·ªán t·∫≠p kh·∫£ nƒÉng tr·∫£ giao b√≥ng hi·ªáu qu·∫£.
4. C√°c ƒë·∫∑c tr∆∞ng kh√°c:
p1_ace_ratio: TƒÉng hi·ªáu qu·∫£ giao b√≥ng ƒë·ªÉ gi·∫£m √°p l·ª±c.
games_diff: T·∫≠p trung duy tr√¨ phong ƒë·ªô ·ªïn ƒë·ªãnh qua c√°c game.
serve_width: ƒêa d·∫°ng h√≥a h∆∞·ªõng giao b√≥ng ƒë·ªÉ l√†m kh√≥ ƒë·ªëi th·ªß.

"""

from sklearn.calibration import calibration_curve
from sklearn.isotonic import IsotonicRegression
import matplotlib.pyplot as plt
import numpy as np

# Cross-validation
from sklearn.model_selection import train_test_split

X_train_iso, X_val_iso, y_train_iso, y_val_iso = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Hu·∫•n luy·ªán m√¥ h√¨nh XGBoost ƒë·ªÉ t·∫°o x√°c su·∫•t
ensemble_model.fit(X_train_iso, y_train_iso)
y_val_prob = ensemble_model.predict_proba(X_val_iso)[:, 1]

# Hu·∫•n luy·ªán Isotonic Regression
isotonic = IsotonicRegression(out_of_bounds="clip")
isotonic.fit(y_val_prob, y_val_iso)

# Hi·ªáu ch·ªânh x√°c su·∫•t
y_val_prob_calibrated = isotonic.predict(y_val_prob)

# So s√°nh Calibration Curve
prob_true, prob_pred = calibration_curve(y_val_iso, y_val_prob, n_bins=10)
prob_true_calibrated, prob_pred_calibrated = calibration_curve(y_val_iso, y_val_prob_calibrated, n_bins=10)

plt.figure(figsize=(10, 5))
plt.plot(prob_pred, prob_true, "s-", label="Original Probabilities")
plt.plot(prob_pred_calibrated, prob_true_calibrated, "o-", label="Calibrated Probabilities (Isotonic)")
plt.plot([0, 1], [0, 1], "k--", label="Perfect Calibration")
plt.xlabel("Predicted Probability")
plt.ylabel("Fraction of Positives")
plt.title("Calibration Curve")
plt.legend()
plt.show()

from sklearn.metrics import log_loss, brier_score_loss

original_log_loss = log_loss(y_val_iso, y_val_prob)
calibrated_log_loss = log_loss(y_val_iso, y_val_prob_calibrated)

original_brier_score = brier_score_loss(y_val_iso, y_val_prob)
calibrated_brier_score = brier_score_loss(y_val_iso, y_val_prob_calibrated)

print(f"Original Log Loss: {original_log_loss:.4f}")
print(f"Calibrated Log Loss: {calibrated_log_loss:.4f}")
print(f"Original Brier Score: {original_brier_score:.4f}")
print(f"Calibrated Brier Score: {calibrated_brier_score:.4f}")

"""Log Loss:

Original Log Loss l√† 0.4850, sau hi·ªáu ch·ªânh b·∫±ng Isotonic Regression gi·∫£m xu·ªëng c√≤n 0.4638.
Vi·ªác gi·∫£m Log Loss cho th·∫•y r·∫±ng m√¥ h√¨nh sau hi·ªáu ch·ªânh x√°c su·∫•t ph√π h·ª£p h∆°n v·ªõi th·ª±c t·∫ø.
X√°c su·∫•t ƒë·∫ßu ra ƒë√£ gi·∫£m b·ªõt s·ª± kh√°c bi·ªát gi·ªØa gi√° tr·ªã d·ª± ƒëo√°n v√† nh√£n th·ª±c t·∫ø, l√†m tƒÉng ƒë·ªô tin c·∫≠y c·ªßa m√¥ h√¨nh trong vi·ªác d·ª± ƒëo√°n x√°c su·∫•t.
Brier Score:

Original Brier Score l√† 0.1649, sau hi·ªáu ch·ªânh gi·∫£m xu·ªëng c√≤n 0.1587.
ƒêi·ªÅu n√†y ch·ª©ng minh r·∫±ng d·ª± ƒëo√°n x√°c su·∫•t sau hi·ªáu ch·ªânh kh√¥ng ch·ªâ ch√≠nh x√°c h∆°n m√† c√≤n g·∫ßn h∆°n v·ªõi nh√£n th·ª±c t·∫ø tr√™n to√†n b·ªô t·∫≠p d·ªØ li·ªáu.

M·ª•c ti√™u hi·ªÉu ch·ªânh l√† ƒë·ªÉ  gi√∫p c√°c x√°c su·∫•t d·ª± ƒëo√°n ph·∫£n √°nh ch√≠nh x√°c t·∫ßn su·∫•t th·ª±c t·∫ø.
"""

from sklearn.isotonic import IsotonicRegression
from sklearn.calibration import calibration_curve
from sklearn.metrics import brier_score_loss, log_loss
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import VotingClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, precision_score, recall_score, f1_score
from tabulate import tabulate


# Assuming X_train, y_train, X_val are defined from the previous code

# Cross-validation (example using a subset of X_train)
X_train_iso, X_val_iso, y_train_iso, y_val_iso = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# ... (previous code for defining and training ensemble_model) ...


# Hu·∫•n luy·ªán m√¥ h√¨nh ƒë·ªÉ t·∫°o x√°c su·∫•t (ensemble_model is assumed to be defined)
ensemble_model.fit(X_train_iso, y_train_iso)
y_val_prob = ensemble_model.predict_proba(X_val_iso)[:, 1]

# Hu·∫•n luy·ªán Isotonic Regression
isotonic = IsotonicRegression(out_of_bounds="clip")
isotonic.fit(y_val_prob, y_val_iso)

# Hi·ªáu ch·ªânh x√°c su·∫•t
y_val_prob_calibrated = isotonic.predict(y_val_prob)

# So s√°nh Calibration Curve
prob_true, prob_pred = calibration_curve(y_val_iso, y_val_prob, n_bins=10)
prob_true_calibrated, prob_pred_calibrated = calibration_curve(y_val_iso, y_val_prob_calibrated, n_bins=10)

plt.figure(figsize=(10, 5))
plt.plot(prob_pred, prob_true, "s-", label="Original Probabilities")
plt.plot(prob_pred_calibrated, prob_true_calibrated, "o-", label="Calibrated Probabilities (Isotonic)")
plt.plot([0, 1], [0, 1], "k--", label="Perfect Calibration")
plt.xlabel("Predicted Probability")
plt.ylabel("Fraction of Positives")
plt.title("Calibration Curve")
plt.legend()
plt.show()


original_log_loss = log_loss(y_val_iso, y_val_prob)
calibrated_log_loss = log_loss(y_val_iso, y_val_prob_calibrated)

original_brier_score = brier_score_loss(y_val_iso, y_val_prob)
calibrated_brier_score = brier_score_loss(y_val_iso, y_val_prob_calibrated)

print(f"Original Log Loss: {original_log_loss:.4f}")
print(f"Calibrated Log Loss: {calibrated_log_loss:.4f}")
print(f"Original Brier Score: {original_brier_score:.4f}")
print(f"Calibrated Brier Score: {calibrated_brier_score:.4f}")

import matplotlib.pyplot as plt
from sklearn.calibration import IsotonicRegression
from sklearn.metrics import roc_curve, auc

y_prob_original = ensemble_model.predict_proba(X_test)[:, 1]

# Hi·ªáu ch·ªânh x√°c su·∫•t b·∫±ng Isotonic Regression
isotonic = IsotonicRegression(out_of_bounds='clip')
isotonic.fit(y_prob_original, y_test)
y_prob_calibrated = isotonic.predict(y_prob_original)

# ROC Curve (Tr·ª±c quan h√≥a)
fpr_original, tpr_original, _ = roc_curve(y_test, y_prob_original)
roc_auc_original = auc(fpr_original, tpr_original)

fpr_calibrated, tpr_calibrated, _ = roc_curve(y_test, y_prob_calibrated)
roc_auc_calibrated = auc(fpr_calibrated, tpr_calibrated)

plt.figure(figsize=(10, 6))
plt.plot(fpr_original, tpr_original, label=f"Original ROC Curve (AUC = {roc_auc_original:.3f})", linestyle='--', color='blue')
plt.plot(fpr_calibrated, tpr_calibrated, label=f"Calibrated ROC Curve (AUC = {roc_auc_calibrated:.3f})", color='red')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label="Random Guess")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve: Original vs. Calibrated Probabilities")
plt.legend(loc="lower right")
plt.show()

# Histogram (Tr·ª±c quan h√≥a x√°c su·∫•t)
plt.figure(figsize=(10, 6))
plt.hist(y_prob_original, bins=20, alpha=0.5, label="Original Probabilities", color="blue")
plt.hist(y_prob_calibrated, bins=20, alpha=0.5, label="Calibrated Probabilities", color="red")
plt.xlabel("Predicted Probabilities")
plt.ylabel("Frequency")
plt.title("Histogram of Original vs. Calibrated Probabilities")
plt.legend(loc="upper center")
plt.show()

# K·∫øt qu·∫£ Log Loss v√† Brier Score
from sklearn.metrics import log_loss, brier_score_loss

log_loss_original = log_loss(y_test, y_prob_original)
log_loss_calibrated = log_loss(y_test, y_prob_calibrated)
brier_score_original = brier_score_loss(y_test, y_prob_original)
brier_score_calibrated = brier_score_loss(y_test, y_prob_calibrated)

print(f"Original Log Loss: {log_loss_original:.4f}")
print(f"Calibrated Log Loss: {log_loss_calibrated:.4f}")
print(f"Original Brier Score: {brier_score_original:.4f}")
print(f"Calibrated Brier Score: {brier_score_calibrated:.4f}")

predicted_probabilities = ensemble_model.predict_proba(data_train.drop('point_victor_p1'))[:, 1]  # X√°c su·∫•t l·ªõp 1 (positive class)

# Th√™m c·ªôt x√°c su·∫•t v√†o DataFrame X
X_with_prob = X.copy()
X_with_prob['Predicted_Probability'] = predicted_probabilities

# Gi·∫£ s·ª≠ 'escape_time' l√† m·ªôt c·ªôt trong X li√™n quan ƒë·∫øn th·ªùi gian ho·∫∑c m·ªôt gi√° tr·ªã li√™n t·ª•c
# S·∫Øp x·∫øp d·ªØ li·ªáu theo escape_time ƒë·ªÉ tr·ª±c quan h√≥a
if 'elapsed_time_seconds' in X.columns:
    X_with_prob = X_with_prob.sort_values(by='elapsed_time_seconds')

# Tr·ª±c quan h√≥a x√°c su·∫•t theo escape_time
plt.figure(figsize=(10, 6))
plt.plot(X_with_prob['elapsed_time_seconds'], X_with_prob['Predicted_Probability'], label='Predicted Probability', color='blue')
plt.xlabel("Escape Time")
plt.ylabel("Predicted Probability")
plt.title("Predicted Probability vs Escape Time")
plt.legend()
plt.grid(True)
plt.show()

print("S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng trong m√¥ h√¨nh:", ensemble_model.estimators_[0].n_features_in_)
print("S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng trong X:", data_train.shape[1])

print(data_train)